{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afe013cf-93b1-4d0d-9544-b2ab6e861195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data prepared for AI training!\n",
      "Training data shape: (79, 1)\n",
      "Testing data shape: (20, 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load BTC data\n",
    "data_path = os.path.join(\"..\", \"data\", \"btc_usd_data.csv\")  # Adjust path if needed\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Sort by time (in case data is shuffled)\n",
    "df = df.sort_values(by=\"timestamp\")\n",
    "\n",
    "# Select only 'close' price for training\n",
    "df['future_price'] = df['close'].shift(-1)  # Shift data to predict the next price\n",
    "\n",
    "# Remove NaN values (last row will have NaN)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Features (X) and Target (Y)\n",
    "X = df[['close']]  # Using only the last closing price as input\n",
    "y = df['future_price']  # Target is the next price\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset into 80% Training & 20% Testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"âœ… Data prepared for AI training!\")\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faa77a77-db5f-4fb0-ba91-cff8b4dbffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load BTC data\n",
    "data_path = os.path.join(\"..\", \"data\", \"btc_usd_data.csv\")  # Adjust path if needed\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Sort by time (in case data is shuffled)\n",
    "df = df.sort_values(by=\"timestamp\")\n",
    "\n",
    "# Select only 'close' price for training\n",
    "df['future_price'] = df['close'].shift(-1)  # Shift data to predict the next price\n",
    "\n",
    "# Remove NaN values (last row will have NaN)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Features (X) and Target (Y)\n",
    "X = df[['close']]  # Using only the last closing price as input\n",
    "y = df['future_price']  # Target is the next price\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset into 80% Training &\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7569934a-0675-47f8-ad1e-d47597a0511e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (79, 1)\n",
      "y_train shape: (79,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1f0db55-e46e-4f8d-984c-50bc6f85cf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training the AI model...\n",
      "âœ… AI Model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Train the AI Model\n",
    "print(\"âœ… Training the AI model...\")\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on Test Data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"âœ… AI Model trained successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13635bfe-2644-4355-8f88-312039db9f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 5 Actual Prices:\", y_test[:5].values)\n",
    "print(\"First 5 Predicted Prices:\", y_pred[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22a7d642-91fc-4406-8f9e-c871ec2fd878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 Actual Prices: [86956.1 90336.  86030.1 90067.  85993. ]\n",
      "First 5 Predicted Prices: [87793.71789002 89780.04902302 86184.51575361 90473.07263524\n",
      " 86047.4629254 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"First 5 Actual Prices:\", y_test[:5].values)\n",
    "print(\"First 5 Predicted Prices:\", y_pred[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cf099e4-cd9d-47ee-ab9f-0a1ddd0b3283",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_absolute_error, mean_squared_error\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m mae \u001b[38;5;241m=\u001b[39m mean_absolute_error(\u001b[43my_test\u001b[49m, y_pred)\n\u001b[0;32m      5\u001b[0m mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, y_pred)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸ“Š Mean Absolute Error (MAE): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmae\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"ðŸ“Š Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"ðŸ“‰ Mean Squared Error (MSE): {mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "716eb465-1175-4804-a079-e59feed9bbf7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2290755842.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    Vfrom sklearn.metrics import mean_absolute_error, mean_squared_error\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Vfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"ðŸ“Š Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"ðŸ“‰ Mean Squared Error (MSE): {mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b8bc547-07a7-459c-8e42-50a49ba24759",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_absolute_error, mean_squared_error\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m mae \u001b[38;5;241m=\u001b[39m mean_absolute_error(\u001b[43my_test\u001b[49m, y_pred)\n\u001b[0;32m      5\u001b[0m mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, y_pred)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸ“Š Mean Absolute Error (MAE): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmae\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"ðŸ“Š Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"ðŸ“‰ Mean Squared Error (MSE): {mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4343a87c-ce2c-4f38-955e-d092d75fde05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Error: name 'y_test' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Check if y_test and y_pred exist\n",
    "try:\n",
    "    print(\"y_test shape:\", y_test.shape)\n",
    "    print(\"y_pred shape:\", y_pred.shape)\n",
    "except NameError as e:\n",
    "    print(f\"âŒ Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "173d3555-ddfd-42c1-a185-ff01cca64644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data prepared for AI training!\n",
      "Training data shape: (79, 1)\n",
      "Testing data shape: (20, 1)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load BTC data\n",
    "data_path = os.path.join(\"..\", \"data\", \"btc_usd_data.csv\")  # Adjust path if needed\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Sort by time (in case data is shuffled)\n",
    "df = df.sort_values(by=\"timestamp\")\n",
    "\n",
    "# Select only 'close' price for training\n",
    "df['future_price'] = df['close'].shift(-1)  # Shift data to predict the next price\n",
    "\n",
    "# Remove NaN values (last row will have NaN)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Features (X) and Target (Y)\n",
    "X = df[['close']]  # Using only the last closing price as input\n",
    "y = df['future_price']  # Target is the next price\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split dataset into 80% Training & 20% Testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"âœ… Data prepared for AI training!\")\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a8f83b6-79fb-4b2d-8efc-ebb6ea40fbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… AI Model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Train the AI Model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on Test Data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"âœ… AI Model trained successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3782f59e-5831-4508-b2e8-b7a59c2d3cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Mean Absolute Error (MAE): 630.75\n",
      "ðŸ“‰ Mean Squared Error (MSE): 1239807.48\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"ðŸ“Š Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"ðŸ“‰ Mean Squared Error (MSE): {mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f16c7ee-8f46-43f4-91cc-ecd84bd6d620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ta\n",
      "  Downloading ta-0.11.0.tar.gz (25 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from ta) (2.2.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from ta) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from pandas->ta) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from pandas->ta) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from pandas->ta) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas->ta) (1.17.0)\n",
      "Building wheels for collected packages: ta\n",
      "  Building wheel for ta (pyproject.toml): started\n",
      "  Building wheel for ta (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for ta: filename=ta-0.11.0-py3-none-any.whl size=29497 sha256=a258f01eaa20a0b7a2e6a8075125916ec4761a1394d304020dac2a2a68f66069\n",
      "  Stored in directory: c:\\users\\18593\\appdata\\local\\pip\\cache\\wheels\\e3\\3a\\ee\\4955a26c90a4b7deb6d725dc8ec7b8604a7aef44e43a2e8af7\n",
      "Successfully built ta\n",
      "Installing collected packages: ta\n",
      "Successfully installed ta-0.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faf06ba4-bbe0-403b-aa05-89cd810282d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-05 05:00:00</td>\n",
       "      <td>86890.1</td>\n",
       "      <td>87161.7</td>\n",
       "      <td>86851.1</td>\n",
       "      <td>87111.0</td>\n",
       "      <td>13.761047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-05 06:00:00</td>\n",
       "      <td>87111.0</td>\n",
       "      <td>87484.1</td>\n",
       "      <td>87011.6</td>\n",
       "      <td>87484.1</td>\n",
       "      <td>15.719382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-05 07:00:00</td>\n",
       "      <td>87484.1</td>\n",
       "      <td>87657.3</td>\n",
       "      <td>87353.1</td>\n",
       "      <td>87600.0</td>\n",
       "      <td>37.084386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03-05 08:00:00</td>\n",
       "      <td>87600.0</td>\n",
       "      <td>87857.4</td>\n",
       "      <td>87597.5</td>\n",
       "      <td>87723.4</td>\n",
       "      <td>86.640133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-05 09:00:00</td>\n",
       "      <td>87723.5</td>\n",
       "      <td>88749.4</td>\n",
       "      <td>87665.0</td>\n",
       "      <td>88471.8</td>\n",
       "      <td>70.304579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp     open     high      low    close     volume\n",
       "0 2025-03-05 05:00:00  86890.1  87161.7  86851.1  87111.0  13.761047\n",
       "1 2025-03-05 06:00:00  87111.0  87484.1  87011.6  87484.1  15.719382\n",
       "2 2025-03-05 07:00:00  87484.1  87657.3  87353.1  87600.0  37.084386\n",
       "3 2025-03-05 08:00:00  87600.0  87857.4  87597.5  87723.4  86.640133\n",
       "4 2025-03-05 09:00:00  87723.5  88749.4  87665.0  88471.8  70.304579"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ta  # Technical analysis library\n",
    "\n",
    "# Load BTC data\n",
    "data_path = os.path.join(\"..\", \"data\", \"btc_usd_data.csv\")  # Adjust if needed\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Sort data by time (just in case)\n",
    "df = df.sort_values(by=\"timestamp\")\n",
    "\n",
    "print(\"âœ… Data loaded successfully!\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e35f1d3c-c912-411c-9f41-39f2f065c23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Moving Averages added!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>close</th>\n",
       "      <th>SMA_20</th>\n",
       "      <th>EMA_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2025-03-09 04:00:00</td>\n",
       "      <td>86023.1</td>\n",
       "      <td>86156.655</td>\n",
       "      <td>86264.797269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2025-03-09 05:00:00</td>\n",
       "      <td>86030.1</td>\n",
       "      <td>86163.540</td>\n",
       "      <td>86242.445149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2025-03-09 06:00:00</td>\n",
       "      <td>85876.5</td>\n",
       "      <td>86151.435</td>\n",
       "      <td>86207.593230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2025-03-09 07:00:00</td>\n",
       "      <td>85993.0</td>\n",
       "      <td>86155.030</td>\n",
       "      <td>86187.155779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2025-03-09 08:00:00</td>\n",
       "      <td>86015.2</td>\n",
       "      <td>86145.790</td>\n",
       "      <td>86170.779038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp    close     SMA_20        EMA_20\n",
       "95 2025-03-09 04:00:00  86023.1  86156.655  86264.797269\n",
       "96 2025-03-09 05:00:00  86030.1  86163.540  86242.445149\n",
       "97 2025-03-09 06:00:00  85876.5  86151.435  86207.593230\n",
       "98 2025-03-09 07:00:00  85993.0  86155.030  86187.155779\n",
       "99 2025-03-09 08:00:00  86015.2  86145.790  86170.779038"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add Moving Averages\n",
    "df['SMA_20'] = ta.trend.sma_indicator(df['close'], window=20)  # Simple Moving Average (20 periods)\n",
    "df['EMA_20'] = ta.trend.ema_indicator(df['close'], window=20)  # Exponential Moving Average (20 periods)\n",
    "\n",
    "print(\"âœ… Moving Averages added!\")\n",
    "df[['timestamp', 'close', 'SMA_20', 'EMA_20']].tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e70d8726-034a-4276-a5be-c9f4466fe66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RSI added!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>close</th>\n",
       "      <th>RSI_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2025-03-09 04:00:00</td>\n",
       "      <td>86023.1</td>\n",
       "      <td>43.469751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2025-03-09 05:00:00</td>\n",
       "      <td>86030.1</td>\n",
       "      <td>43.605119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2025-03-09 06:00:00</td>\n",
       "      <td>85876.5</td>\n",
       "      <td>41.269802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2025-03-09 07:00:00</td>\n",
       "      <td>85993.0</td>\n",
       "      <td>43.731273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2025-03-09 08:00:00</td>\n",
       "      <td>86015.2</td>\n",
       "      <td>44.211109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp    close     RSI_14\n",
       "95 2025-03-09 04:00:00  86023.1  43.469751\n",
       "96 2025-03-09 05:00:00  86030.1  43.605119\n",
       "97 2025-03-09 06:00:00  85876.5  41.269802\n",
       "98 2025-03-09 07:00:00  85993.0  43.731273\n",
       "99 2025-03-09 08:00:00  86015.2  44.211109"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add RSI (Relative Strength Index)\n",
    "df['RSI_14'] = ta.momentum.rsi(df['close'], window=14)\n",
    "\n",
    "print(\"âœ… RSI added!\")\n",
    "df[['timestamp', 'close', 'RSI_14']].tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c305961-2676-4fae-8d39-69b41468554d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Volume indicator added!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>volume</th>\n",
       "      <th>Volume_SMA_20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2025-03-09 04:00:00</td>\n",
       "      <td>23.799168</td>\n",
       "      <td>26.247579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2025-03-09 05:00:00</td>\n",
       "      <td>7.325100</td>\n",
       "      <td>25.004431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2025-03-09 06:00:00</td>\n",
       "      <td>13.132160</td>\n",
       "      <td>23.628914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2025-03-09 07:00:00</td>\n",
       "      <td>33.743682</td>\n",
       "      <td>24.641181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2025-03-09 08:00:00</td>\n",
       "      <td>0.090421</td>\n",
       "      <td>22.952806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp     volume  Volume_SMA_20\n",
       "95 2025-03-09 04:00:00  23.799168      26.247579\n",
       "96 2025-03-09 05:00:00   7.325100      25.004431\n",
       "97 2025-03-09 06:00:00  13.132160      23.628914\n",
       "98 2025-03-09 07:00:00  33.743682      24.641181\n",
       "99 2025-03-09 08:00:00   0.090421      22.952806"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add Volume-Based Indicator (Simple Moving Average of Volume)\n",
    "df['Volume_SMA_20'] = ta.trend.sma_indicator(df['volume'], window=20)\n",
    "\n",
    "print(\"âœ… Volume indicator added!\")\n",
    "df[['timestamp', 'volume', 'Volume_SMA_20']].tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3dbf08d9-ae3d-4612-ac03-528639169cf1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'future_price'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'future_price'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSMA_20\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEMA_20\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRSI_14\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVolume_SMA_20\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      6\u001b[0m X \u001b[38;5;241m=\u001b[39m df[features]\n\u001b[1;32m----> 7\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfuture_price\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# Target is still the next BTC closing price\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Normalize the data\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'future_price'"
     ]
    }
   ],
   "source": [
    "# Drop NaN values (because some indicators take time to calculate)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Select new features for training\n",
    "features = ['close', 'SMA_20', 'EMA_20', 'RSI_14', 'Volume_SMA_20']\n",
    "X = df[features]\n",
    "y = df['future_price']  # Target is still the next BTC closing price\n",
    "\n",
    "# Normalize the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split into training & testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"âœ… AI Model now uses technical indicators!\")\n",
    "print(\"New training data shape:\", X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4273a9bc-bdaa-4fcb-9c42-93fa58eb7ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 'future_price' column added back!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>close</th>\n",
       "      <th>future_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2025-03-09 03:00:00</td>\n",
       "      <td>86168.5</td>\n",
       "      <td>86023.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2025-03-09 04:00:00</td>\n",
       "      <td>86023.1</td>\n",
       "      <td>86030.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2025-03-09 05:00:00</td>\n",
       "      <td>86030.1</td>\n",
       "      <td>85876.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2025-03-09 06:00:00</td>\n",
       "      <td>85876.5</td>\n",
       "      <td>85993.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2025-03-09 07:00:00</td>\n",
       "      <td>85993.0</td>\n",
       "      <td>86015.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp    close  future_price\n",
       "94 2025-03-09 03:00:00  86168.5       86023.1\n",
       "95 2025-03-09 04:00:00  86023.1       86030.1\n",
       "96 2025-03-09 05:00:00  86030.1       85876.5\n",
       "97 2025-03-09 06:00:00  85876.5       85993.0\n",
       "98 2025-03-09 07:00:00  85993.0       86015.2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift closing prices to predict the next period's price\n",
    "df['future_price'] = df['close'].shift(-1)  # Predict next closing price\n",
    "\n",
    "# Drop NaN values (last row will have NaN after shifting)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "print(\"âœ… 'future_price' column added back!\")\n",
    "df[['timestamp', 'close', 'future_price']].tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dcf9ced-d0ab-428f-ab30-9bb4c7aa5118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['timestamp', 'open', 'high', 'low', 'close', 'volume', 'SMA_20',\n",
      "       'EMA_20', 'RSI_14', 'Volume_SMA_20', 'future_price'],\n",
      "      dtype='object')\n",
      "             timestamp    close  future_price\n",
      "94 2025-03-09 03:00:00  86168.5       86023.1\n",
      "95 2025-03-09 04:00:00  86023.1       86030.1\n",
      "96 2025-03-09 05:00:00  86030.1       85876.5\n",
      "97 2025-03-09 06:00:00  85876.5       85993.0\n",
      "98 2025-03-09 07:00:00  85993.0       86015.2\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)  # Show all columns\n",
    "print(df[['timestamp', 'close', 'future_price']].tail())  # Show last 5 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "319aaa42-ead8-439a-8d2d-6770fe6a7e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… AI Model now uses technical indicators!\n",
      "New training data shape: (64, 5)\n"
     ]
    }
   ],
   "source": [
    "# Select new features for training\n",
    "features = ['close', 'SMA_20', 'EMA_20', 'RSI_14', 'Volume_SMA_20']\n",
    "X = df[features]\n",
    "y = df['future_price']  # Target is still the next BTC closing price\n",
    "\n",
    "# Normalize the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split into training & testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"âœ… AI Model now uses technical indicators!\")\n",
    "print(\"New training data shape:\", X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "233713e7-be08-4d59-9222-be961a9a270e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tweepy\n",
      "  Downloading tweepy-4.15.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting newsapi-python\n",
      "  Downloading newsapi_python-0.2.7-py2.py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting pytrends\n",
      "  Downloading pytrends-4.9.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting textblob\n",
      "  Downloading textblob-0.19.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting oauthlib<4,>=3.2.0 (from tweepy)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from tweepy) (2.32.3)\n",
      "Collecting requests-oauthlib<3,>=1.2.0 (from tweepy)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from pytrends) (2.2.3)\n",
      "Collecting lxml (from pytrends)\n",
      "  Downloading lxml-5.3.1-cp313-cp313-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting nltk>=3.9 (from textblob)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from nltk>=3.9->textblob) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from nltk>=3.9->textblob) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from nltk>=3.9->textblob) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from pandas>=0.25->pytrends) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from pandas>=0.25->pytrends) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from pandas>=0.25->pytrends) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from pandas>=0.25->pytrends) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2.27.0->tweepy) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2.27.0->tweepy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2.27.0->tweepy) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2.27.0->tweepy) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas>=0.25->pytrends) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from click->nltk>=3.9->textblob) (0.4.6)\n",
      "Downloading tweepy-4.15.0-py3-none-any.whl (99 kB)\n",
      "Downloading newsapi_python-0.2.7-py2.py3-none-any.whl (7.9 kB)\n",
      "Downloading pytrends-4.9.2-py3-none-any.whl (15 kB)\n",
      "Downloading textblob-0.19.0-py3-none-any.whl (624 kB)\n",
      "   ---------------------------------------- 0.0/624.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 624.3/624.3 kB 14.9 MB/s eta 0:00:00\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 29.1 MB/s eta 0:00:00\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading lxml-5.3.1-cp313-cp313-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.8/3.8 MB 35.1 MB/s eta 0:00:00\n",
      "Installing collected packages: oauthlib, lxml, requests-oauthlib, nltk, newsapi-python, tweepy, textblob, pytrends\n",
      "Successfully installed lxml-5.3.1 newsapi-python-0.2.7 nltk-3.9.1 oauthlib-3.2.2 pytrends-4.9.2 requests-oauthlib-2.0.0 textblob-0.19.0 tweepy-4.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script nltk.exe is installed in 'C:\\Users\\18593\\AppData\\Roaming\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install tweepy newsapi-python pytrends textblob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89c037e2-c8c5-4c51-94d1-4e4dbc3e86cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pytrends in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (4.9.2)\n",
      "Requirement already satisfied: requests>=2.0 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from pytrends) (2.32.3)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from pytrends) (2.2.3)\n",
      "Requirement already satisfied: lxml in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from pytrends) (5.3.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from pandas>=0.25->pytrends) (2.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from pandas>=0.25->pytrends) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from pandas>=0.25->pytrends) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from pandas>=0.25->pytrends) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.0->pytrends) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.0->pytrends) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.0->pytrends) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.0->pytrends) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas>=0.25->pytrends) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytrends\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e39a96a-85d9-4079-8081-5b937a6b2d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytrends.request import TrendReq\n",
    "\n",
    "pytrends = TrendReq(hl=\"en-US\", tz=360)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f9518c2-3f9f-4cd9-b28d-397d16df3c70",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_twitter_sentiment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Add Twitter Sentiment to dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTwitter_Sentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mget_twitter_sentiment\u001b[49m()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… Twitter Sentiment added to dataset!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTwitter_Sentiment\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mtail()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_twitter_sentiment' is not defined"
     ]
    }
   ],
   "source": [
    "# Add Twitter Sentiment to dataset\n",
    "df[\"Twitter_Sentiment\"] = get_twitter_sentiment()\n",
    "\n",
    "print(\"âœ… Twitter Sentiment added to dataset!\")\n",
    "df[['timestamp', 'close', 'Twitter_Sentiment']].tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53bb7510-cc22-4bfa-a1e8-87c200e6e310",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_twitter_sentiment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Test if function returns a sentiment score\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m twitter_sentiment \u001b[38;5;241m=\u001b[39m \u001b[43mget_twitter_sentiment\u001b[49m()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸ“¢ Twitter Sentiment Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtwitter_sentiment\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_twitter_sentiment' is not defined"
     ]
    }
   ],
   "source": [
    "# Test if function returns a sentiment score\n",
    "twitter_sentiment = get_twitter_sentiment()\n",
    "\n",
    "print(f\"ðŸ“¢ Twitter Sentiment Score: {twitter_sentiment:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb131ea7-79b2-4a8c-bf93-9030a3a43383",
   "metadata": {},
   "outputs": [
    {
     "ename": "_IncompleteInputError",
     "evalue": "incomplete input (4158413717.py, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[24], line 28\u001b[1;36m\u001b[0m\n\u001b[1;33m    \u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31m_IncompleteInputError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "from textblob import TextBlob\n",
    "\n",
    "# ðŸ”‘ Twitter API Keys (Replace these with your actual keys)\n",
    "API_KEY = \"your_api_key_here\"\n",
    "API_SECRET = \"your_api_secret_here\"\n",
    "ACCESS_TOKEN = \"your_access_token_here\"\n",
    "ACCESS_SECRET = \"your_access_token_secret_here\"\n",
    "\n",
    "# Authenticate with Twitter API\n",
    "auth = tweepy.OAuthHandler(API_KEY, API_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "# Function to get Twitter sentiment on Bitcoin\n",
    "def get_twitter_sentiment(query=\"Bitcoin\", count=100):\n",
    "    try:\n",
    "        tweets = api.search_tweets(q=query, count=count, lang=\"en\", tweet_mode=\"extended\")\n",
    "        sentiment_scores = []\n",
    "\n",
    "        for tweet in tweets:\n",
    "            analysis = TextBlob(tweet.full_text)\n",
    "            sentiment_scores.append(analysis.sentiment.polarity)  # -1 (negative) to +1 (positive)\n",
    "\n",
    "        avg_sentiment = sum(sentiment_scores) / len(sentiment_scores) if sentiment_scores else 0\n",
    "        return avg_sentiment\n",
    "    except Exception as e:\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37bbd003-f0e7-411a-9fd0-c9848c016ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Twitter Sentiment Function Loaded!\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "from textblob import TextBlob\n",
    "\n",
    "# ðŸ”‘ Twitter API Keys (Replace these with your actual keys)\n",
    "API_KEY = \"your_api_key_here\"\n",
    "API_SECRET = \"your_api_secret_here\"\n",
    "ACCESS_TOKEN = \"your_access_token_here\"\n",
    "ACCESS_SECRET = \"your_access_token_secret_here\"\n",
    "\n",
    "# Authenticate with Twitter API\n",
    "auth = tweepy.OAuthHandler(API_KEY, API_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "# Function to get Twitter sentiment on Bitcoin\n",
    "def get_twitter_sentiment(query=\"Bitcoin\", count=100):\n",
    "    try:\n",
    "        tweets = api.search_tweets(q=query, count=count, lang=\"en\", tweet_mode=\"extended\")\n",
    "        sentiment_scores = []\n",
    "\n",
    "        for tweet in tweets:\n",
    "            analysis = TextBlob(tweet.full_text)  # Analyze tweet text\n",
    "            sentiment_scores.append(analysis.sentiment.polarity)  # -1 (negative) to +1 (positive)\n",
    "\n",
    "        avg_sentiment = sum(sentiment_scores) / len(sentiment_scores) if sentiment_scores else 0\n",
    "        return avg_sentiment\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error getting Twitter sentiment: {e}\")\n",
    "        return 0  # Default to neutral sentiment if error\n",
    "\n",
    "print(\"âœ… Twitter Sentiment Function Loaded!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de20f7a8-4252-4016-b611-f1e4b2605606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Error getting Twitter sentiment: 401 Unauthorized\n",
      "89 - Invalid or expired token.\n",
      "ðŸ“¢ Twitter Sentiment Score: 0.00\n"
     ]
    }
   ],
   "source": [
    "twitter_sentiment = get_twitter_sentiment()\n",
    "print(f\"ðŸ“¢ Twitter Sentiment Score: {twitter_sentiment:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b6d6fbd-31f5-468a-860b-3197f3dcf6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Twitter Sentiment added to dataset!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>close</th>\n",
       "      <th>Twitter_Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2025-03-09 03:00:00</td>\n",
       "      <td>86168.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2025-03-09 04:00:00</td>\n",
       "      <td>86023.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2025-03-09 05:00:00</td>\n",
       "      <td>86030.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2025-03-09 06:00:00</td>\n",
       "      <td>85876.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2025-03-09 07:00:00</td>\n",
       "      <td>85993.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp    close  Twitter_Sentiment\n",
       "94 2025-03-09 03:00:00  86168.5                  0\n",
       "95 2025-03-09 04:00:00  86023.1                  0\n",
       "96 2025-03-09 05:00:00  86030.1                  0\n",
       "97 2025-03-09 06:00:00  85876.5                  0\n",
       "98 2025-03-09 07:00:00  85993.0                  0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Twitter_Sentiment\"] = twitter_sentiment\n",
    "print(\"âœ… Twitter Sentiment added to dataset!\")\n",
    "df[['timestamp', 'close', 'Twitter_Sentiment']].tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "320a09e9-bb2b-45cf-93c8-8d766d1c7300",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (4040135376.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[30], line 7\u001b[1;36m\u001b[0m\n\u001b[1;33m    newsapi = NewsApiClient(api_key=1041ba3ccac645958e26147bf3a204f6)\u001b[0m\n\u001b[1;37m                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "from pytrends.request import TrendReq\n",
    "from newsapi import NewsApiClient\n",
    "\n",
    "# ðŸ”‘ Replace with your News API key (sign up at https://newsapi.org/)\n",
    "newsapi = NewsApiClient(api_key=\"1041ba3ccac645958e26147bf3a204f6\")  # âœ… Correct\n",
    "\n",
    "newsapi = NewsApiClient(api_key=1041ba3ccac645958e26147bf3a204f6)\n",
    "\n",
    "# Connect to Google Trends API\n",
    "pytrends = TrendReq(hl=\"en-US\", tz=360)\n",
    "\n",
    "# Function to get Google Trends sentiment on Bitcoin\n",
    "def get_google_trends_sentiment(keyword=\"Bitcoin\"):\n",
    "    try:\n",
    "        pytrends.build_payload([keyword], cat=0, timeframe=\"now 1-d\", geo=\"\", gprop=\"\")\n",
    "        trend_data = pytrends.interest_over_time()\n",
    "\n",
    "        if not trend_data.empty:\n",
    "            latest_trend = trend_data[keyword].iloc[-1]\n",
    "        else:\n",
    "            latest_trend = 0\n",
    "\n",
    "        return latest_trend\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error getting Google Trends sentiment: {e}\")\n",
    "        return 0  # Default to 0 if error\n",
    "\n",
    "# Function to get Crypto News sentiment\n",
    "def get_crypto_news_sentiment():\n",
    "    try:\n",
    "        articles = newsapi.get_everything(q=\"Bitcoin\", language=\"en\", sort_by=\"publishedAt\", page_size=10)\n",
    "        sentiment_scores = []\n",
    "\n",
    "        for article in articles[\"articles\"]:\n",
    "            analysis = TextBlob(article[\"title\"])\n",
    "            sentiment_scores.append(analysis.sentiment.polarity)  # -1 (negative) to +1 (positive)\n",
    "\n",
    "        avg_sentiment = sum(sentiment_scores) / len(sentiment_scores) if sentiment_scores else 0\n",
    "        return avg_sentiment\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error getting Crypto News sentiment: {e}\")\n",
    "        return 0  # Default to 0 if error\n",
    "\n",
    "# Fetch latest sentiment scores\n",
    "google_trends_score = get_google_trends_sentiment()\n",
    "news_sentiment = get_crypto_news_sentiment()\n",
    "\n",
    "print(f\"ðŸŒŽ Google Trends Score: {google_trends_score}\")\n",
    "print(f\"ðŸ—žï¸ Crypto News Sentiment Score: {news_sentiment:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "506d8348-dff2-4d8c-a30e-2e6a31d60d36",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (4040135376.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[30], line 7\u001b[1;36m\u001b[0m\n\u001b[1;33m    newsapi = NewsApiClient(api_key=1041ba3ccac645958e26147bf3a204f6)\u001b[0m\n\u001b[1;37m                                       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "from pytrends.request import TrendReq\n",
    "from newsapi import NewsApiClient\n",
    "\n",
    "# ðŸ”‘ Replace with your News API key (sign up at https://newsapi.org/)\n",
    "newsapi = NewsApiClient(api_key=\"1041ba3ccac645958e26147bf3a204f6\")  # âœ… Correct\n",
    "\n",
    "newsapi = NewsApiClient(api_key=1041ba3ccac645958e26147bf3a204f6)\n",
    "\n",
    "# Connect to Google Trends API\n",
    "pytrends = TrendReq(hl=\"en-US\", tz=360)\n",
    "\n",
    "# Function to get Google Trends sentiment on Bitcoin\n",
    "def get_google_trends_sentiment(keyword=\"Bitcoin\"):\n",
    "    try:\n",
    "        pytrends.build_payload([keyword], cat=0, timeframe=\"now 1-d\", geo=\"\", gprop=\"\")\n",
    "        trend_data = pytrends.interest_over_time()\n",
    "\n",
    "        if not trend_data.empty:\n",
    "            latest_trend = trend_data[keyword].iloc[-1]\n",
    "        else:\n",
    "            latest_trend = 0\n",
    "\n",
    "        return latest_trend\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error getting Google Trends sentiment: {e}\")\n",
    "        return 0  # Default to 0 if error\n",
    "\n",
    "# Function to get Crypto News sentiment\n",
    "def get_crypto_news_sentiment():\n",
    "    try:\n",
    "        articles = newsapi.get_everything(q=\"Bitcoin\", language=\"en\", sort_by=\"publishedAt\", page_size=10)\n",
    "        sentiment_scores = []\n",
    "\n",
    "        for article in articles[\"articles\"]:\n",
    "            analysis = TextBlob(article[\"title\"])\n",
    "            sentiment_scores.append(analysis.sentiment.polarity)  # -1 (negative) to +1 (positive)\n",
    "\n",
    "        avg_sentiment = sum(sentiment_scores) / len(sentiment_scores) if sentiment_scores else 0\n",
    "        return avg_sentiment\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error getting Crypto News sentiment: {e}\")\n",
    "        return 0  # Default to 0 if error\n",
    "\n",
    "# Fetch latest sentiment scores\n",
    "google_trends_score = get_google_trends_sentiment()\n",
    "news_sentiment = get_crypto_news_sentiment()\n",
    "\n",
    "print(f\"ðŸŒŽ Google Trends Score: {google_trends_score}\")\n",
    "print(f\"ðŸ—žï¸ Crypto News Sentiment Score: {news_sentiment:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "628084cc-f182-4da2-bc76-1b59e0aebd08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ—žï¸ Crypto News Sentiment Score: -0.03\n"
     ]
    }
   ],
   "source": [
    "from newsapi import NewsApiClient\n",
    "\n",
    "# ðŸ”‘ Replace with your News API key\n",
    "NEWS_API_KEY = \"1041ba3ccac645958e26147bf3a204f6\"\n",
    "newsapi = NewsApiClient(api_key=NEWS_API_KEY)\n",
    "\n",
    "def get_crypto_news_sentiment():\n",
    "    try:\n",
    "        articles = newsapi.get_everything(q=\"Bitcoin\", language=\"en\", sort_by=\"publishedAt\", page_size=10)\n",
    "        sentiment_scores = []\n",
    "\n",
    "        for article in articles[\"articles\"]:\n",
    "            analysis = TextBlob(article[\"title\"])\n",
    "            sentiment_scores.append(analysis.sentiment.polarity)  # -1 (negative) to +1 (positive)\n",
    "\n",
    "        avg_sentiment = sum(sentiment_scores) / len(sentiment_scores) if sentiment_scores else 0\n",
    "        return avg_sentiment\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error getting Crypto News sentiment: {e}\")\n",
    "        return 0  # Default to 0 if error\n",
    "\n",
    "# Test the function\n",
    "news_sentiment = get_crypto_news_sentiment()\n",
    "print(f\"ðŸ—žï¸ Crypto News Sentiment Score: {news_sentiment:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d442cc3-fcf6-44a6-bfc9-461924d10a32",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'google_trends_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Add sentiment scores to dataset\u001b[39;00m\n\u001b[0;32m      2\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTwitter_Sentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m twitter_sentiment\n\u001b[1;32m----> 3\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGoogle_Trends\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mgoogle_trends_score\u001b[49m\n\u001b[0;32m      4\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNews_Sentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m news_sentiment\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… Sentiment analysis added to dataset!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'google_trends_score' is not defined"
     ]
    }
   ],
   "source": [
    "# Add sentiment scores to dataset\n",
    "df[\"Twitter_Sentiment\"] = twitter_sentiment\n",
    "df[\"Google_Trends\"] = google_trends_score\n",
    "df[\"News_Sentiment\"] = news_sentiment\n",
    "\n",
    "print(\"âœ… Sentiment analysis added to dataset!\")\n",
    "df[['timestamp', 'close', 'Twitter_Sentiment', 'Google_Trends', 'News_Sentiment']].tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02b24b9c-c616-40ee-8ed2-e7587ed09088",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4088205613.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[33], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    ---------------------------------------------------------------------------\u001b[0m\n\u001b[1;37m                                                                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "---------------------------------------------------------------------------\n",
    "NameError                                 Traceback (most recent call last)\n",
    "Cell In[32], line 3\n",
    "      1 # Add sentiment scores to dataset\n",
    "      2 df[\"Twitter_Sentiment\"] = twitter_sentiment\n",
    "----> 3 df[\"Google_Trends\"] = google_trends_score\n",
    "      4 df[\"News_Sentiment\"] = news_sentiment\n",
    "      6 print(\"âœ… Sentiment analysis added to dataset!\")\n",
    "\n",
    "NameError: name 'google_trends_score' is not defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "852a3334-4ad2-42c0-a775-f2fba8ca5cee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'google_trends_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Add sentiment scores to dataset\u001b[39;00m\n\u001b[0;32m      2\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTwitter_Sentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m twitter_sentiment\n\u001b[1;32m----> 3\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGoogle_Trends\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mgoogle_trends_score\u001b[49m\n\u001b[0;32m      4\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNews_Sentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m news_sentiment\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mâœ… Sentiment analysis added to dataset!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'google_trends_score' is not defined"
     ]
    }
   ],
   "source": [
    "# Add sentiment scores to dataset\n",
    "df[\"Twitter_Sentiment\"] = twitter_sentiment\n",
    "df[\"Google_Trends\"] = google_trends_score\n",
    "df[\"News_Sentiment\"] = news_sentiment\n",
    "\n",
    "print(\"âœ… Sentiment analysis added to dataset!\")\n",
    "df[['timestamp', 'close', 'Twitter_Sentiment', 'Google_Trends', 'News_Sentiment']].tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e58dc73-2da7-45a5-99d7-6c723e4f4ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŒŽ Google Trends Score: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18593\\AppData\\Roaming\\Python\\Python313\\site-packages\\pytrends\\request.py:260: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(False)\n"
     ]
    }
   ],
   "source": [
    "from pytrends.request import TrendReq\n",
    "\n",
    "# Connect to Google Trends API\n",
    "pytrends = TrendReq(hl=\"en-US\", tz=360)\n",
    "\n",
    "# Function to get Google Trends sentiment on Bitcoin\n",
    "def get_google_trends_sentiment(keyword=\"Bitcoin\"):\n",
    "    try:\n",
    "        pytrends.build_payload([keyword], cat=0, timeframe=\"now 1-d\", geo=\"\", gprop=\"\")\n",
    "        trend_data = pytrends.interest_over_time()\n",
    "\n",
    "        if not trend_data.empty:\n",
    "            latest_trend = trend_data[keyword].iloc[-1]\n",
    "        else:\n",
    "            latest_trend = 0\n",
    "\n",
    "        return latest_trend\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error getting Google Trends sentiment: {e}\")\n",
    "        return 0  # Default to 0 if error\n",
    "\n",
    "# Fetch latest Google Trends Score\n",
    "google_trends_score = get_google_trends_sentiment()\n",
    "print(f\"ðŸŒŽ Google Trends Score: {google_trends_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "097da4b6-9ca1-4dcd-9d7d-ba02666a4f1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Bitcoin  isPartial\n",
      "date                                   \n",
      "2025-03-08 09:28:00       77      False\n",
      "2025-03-08 09:36:00       78      False\n",
      "2025-03-08 09:44:00       81      False\n",
      "2025-03-08 09:52:00       78      False\n",
      "2025-03-08 10:00:00       79      False\n",
      "...                      ...        ...\n",
      "2025-03-09 08:56:00       76      False\n",
      "2025-03-09 09:04:00       73      False\n",
      "2025-03-09 09:12:00       73      False\n",
      "2025-03-09 09:20:00       70      False\n",
      "2025-03-09 09:28:00       74       True\n",
      "\n",
      "[181 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18593\\AppData\\Roaming\\Python\\Python313\\site-packages\\pytrends\\request.py:260: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.fillna(False)\n"
     ]
    }
   ],
   "source": [
    "from pytrends.request import TrendReq\n",
    "\n",
    "# Connect to Google Trends\n",
    "pytrends = TrendReq(hl=\"en-US\", tz=360)\n",
    "\n",
    "# Request Bitcoin search interest\n",
    "pytrends.build_payload([\"Bitcoin\"], cat=0, timeframe=\"now 1-d\", geo=\"\", gprop=\"\")\n",
    "trend_data = pytrends.interest_over_time()\n",
    "\n",
    "# Display data\n",
    "print(trend_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70b1127a-0e31-436b-84f4-3b497f20d74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Sentiment analysis added to dataset!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>close</th>\n",
       "      <th>Twitter_Sentiment</th>\n",
       "      <th>Google_Trends</th>\n",
       "      <th>News_Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2025-03-09 03:00:00</td>\n",
       "      <td>86168.5</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>-0.032569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2025-03-09 04:00:00</td>\n",
       "      <td>86023.1</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>-0.032569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2025-03-09 05:00:00</td>\n",
       "      <td>86030.1</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>-0.032569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2025-03-09 06:00:00</td>\n",
       "      <td>85876.5</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>-0.032569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2025-03-09 07:00:00</td>\n",
       "      <td>85993.0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>-0.032569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp    close  Twitter_Sentiment  Google_Trends  \\\n",
       "94 2025-03-09 03:00:00  86168.5                  0             75   \n",
       "95 2025-03-09 04:00:00  86023.1                  0             75   \n",
       "96 2025-03-09 05:00:00  86030.1                  0             75   \n",
       "97 2025-03-09 06:00:00  85876.5                  0             75   \n",
       "98 2025-03-09 07:00:00  85993.0                  0             75   \n",
       "\n",
       "    News_Sentiment  \n",
       "94       -0.032569  \n",
       "95       -0.032569  \n",
       "96       -0.032569  \n",
       "97       -0.032569  \n",
       "98       -0.032569  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add sentiment scores to dataset\n",
    "df[\"Twitter_Sentiment\"] = twitter_sentiment\n",
    "df[\"Google_Trends\"] = google_trends_score\n",
    "df[\"News_Sentiment\"] = news_sentiment\n",
    "\n",
    "print(\"âœ… Sentiment analysis added to dataset!\")\n",
    "df[['timestamp', 'close', 'Twitter_Sentiment', 'Google_Trends', 'News_Sentiment']].tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "03a55aae-ebfe-436a-bad7-89da9019a351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… AI Model now includes sentiment analysis!\n",
      "New training data shape: (64, 8)\n"
     ]
    }
   ],
   "source": [
    "# Drop NaN values (some indicators take time to calculate)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Select new features for training (now includes sentiment)\n",
    "features = [\"close\", \"SMA_20\", \"EMA_20\", \"RSI_14\", \"Volume_SMA_20\", \"Twitter_Sentiment\", \"Google_Trends\", \"News_Sentiment\"]\n",
    "X = df[features]\n",
    "y = df[\"future_price\"]  # Target variable\n",
    "\n",
    "# Normalize the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split into training & testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"âœ… AI Model now includes sentiment analysis!\")\n",
    "print(\"New training data shape:\", X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ece6a73-c52e-4d5b-98e4-aa0bd7a61453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… AI Model retrained with sentiment analysis!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Train AI Model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on Test Data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"âœ… AI Model retrained with sentiment analysis!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2775df0a-024e-4f29-b9fa-a0a0106a8308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Mean Absolute Error (MAE): 466.08\n",
      "ðŸ“‰ Mean Squared Error (MSE): 294464.52\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# Evaluate AI performance\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"ðŸ“Š Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"ðŸ“‰ Mean Squared Error (MSE): {mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "85f65970-a1ef-45a8-8a37-95900a441818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ˆ AI Predicted Next BTC Closing Price: $85967.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\18593\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Predict the next BTC closing price using latest sentiment data\n",
    "latest_data = np.array([df[features].iloc[-1]])  # Get latest data row\n",
    "latest_data_scaled = scaler.transform(latest_data)  # Normalize\n",
    "predicted_price = model.predict(latest_data_scaled)  # Predict\n",
    "\n",
    "print(f\"ðŸ“ˆ AI Predicted Next BTC Closing Price: ${predicted_price[0]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5728a78d-734c-4c9e-be86-614802041fd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             timestamp    close  Predicted_Change Signal\n",
      "89 2025-03-08 22:00:00  86310.9          0.003374   HOLD\n",
      "90 2025-03-08 23:00:00  86164.1               NaN   HOLD\n",
      "91 2025-03-09 00:00:00  86385.5               NaN   HOLD\n",
      "92 2025-03-09 01:00:00  86171.9               NaN   HOLD\n",
      "93 2025-03-09 02:00:00  86047.5               NaN   HOLD\n",
      "94 2025-03-09 03:00:00  86168.5               NaN   HOLD\n",
      "95 2025-03-09 04:00:00  86023.1               NaN   HOLD\n",
      "96 2025-03-09 05:00:00  86030.1               NaN   HOLD\n",
      "97 2025-03-09 06:00:00  85876.5               NaN   HOLD\n",
      "98 2025-03-09 07:00:00  85993.0               NaN   HOLD\n"
     ]
    }
   ],
   "source": [
    "# Define buy/sell thresholds\n",
    "BUY_THRESHOLD = 0.005  # 0.5% increase to trigger buy\n",
    "SELL_THRESHOLD = -0.005  # -0.5% drop to trigger sell\n",
    "\n",
    "# Create trading signals\n",
    "df[\"Predicted_Change\"] = (y_pred - y_test) / y_test  # % change prediction\n",
    "\n",
    "# Generate trading signals\n",
    "df[\"Signal\"] = \"HOLD\"  # Default action\n",
    "df.loc[df[\"Predicted_Change\"] > BUY_THRESHOLD, \"Signal\"] = \"BUY\"\n",
    "df.loc[df[\"Predicted_Change\"] < SELL_THRESHOLD, \"Signal\"] = \"SELL\"\n",
    "\n",
    "# Show last 10 predictions with signals\n",
    "print(df[[\"timestamp\", \"close\", \"Predicted_Change\", \"Signal\"]].tail(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b0c30d6a-d637-419c-8255-5cd0534aa9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal\n",
      "HOLD    73\n",
      "SELL     7\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Signal\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2ccb46bf-cf93-4656-9e07-df6b8ba43690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal\n",
      "HOLD    73\n",
      "SELL     7\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Signal\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ec2e875c-8ed7-4b02-bedc-e60e3a8f821c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             timestamp    close  Predicted_Change Signal\n",
      "89 2025-03-08 22:00:00  86310.9          0.003374    BUY\n",
      "90 2025-03-08 23:00:00  86164.1               NaN   HOLD\n",
      "91 2025-03-09 00:00:00  86385.5               NaN   HOLD\n",
      "92 2025-03-09 01:00:00  86171.9               NaN   HOLD\n",
      "93 2025-03-09 02:00:00  86047.5               NaN   HOLD\n",
      "94 2025-03-09 03:00:00  86168.5               NaN   HOLD\n",
      "95 2025-03-09 04:00:00  86023.1               NaN   HOLD\n",
      "96 2025-03-09 05:00:00  86030.1               NaN   HOLD\n",
      "97 2025-03-09 06:00:00  85876.5               NaN   HOLD\n",
      "98 2025-03-09 07:00:00  85993.0               NaN   HOLD\n"
     ]
    }
   ],
   "source": [
    "BUY_THRESHOLD = 0.002  # Reduce from 0.005 to 0.2% increase\n",
    "SELL_THRESHOLD = -0.002  # Reduce from -0.005 to -0.2% drop\n",
    "\n",
    "# Recalculate trading signals\n",
    "df[\"Signal\"] = \"HOLD\"  # Default action\n",
    "df.loc[df[\"Predicted_Change\"] > BUY_THRESHOLD, \"Signal\"] = \"BUY\"\n",
    "df.loc[df[\"Predicted_Change\"] < SELL_THRESHOLD, \"Signal\"] = \"SELL\"\n",
    "\n",
    "# Show updated trade signals\n",
    "print(df[[\"timestamp\", \"close\", \"Predicted_Change\", \"Signal\"]].tail(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d782d034-0836-4e22-83ec-8dcd4b837e2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'place_trade' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplace_trade\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBUY\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Force a test buy order\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'place_trade' is not defined"
     ]
    }
   ],
   "source": [
    "place_trade(\"BUY\")  # Force a test buy order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "67a74085-74cb-4023-a8c5-361e7578c2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting krakenex\n",
      "  Downloading krakenex-2.2.2.tar.gz (39 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: requests<3,>=2.18.2 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from krakenex) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2.18.2->krakenex) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2.18.2->krakenex) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2.18.2->krakenex) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from requests<3,>=2.18.2->krakenex) (2025.1.31)\n",
      "Building wheels for collected packages: krakenex\n",
      "  Building wheel for krakenex (pyproject.toml): started\n",
      "  Building wheel for krakenex (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for krakenex: filename=krakenex-2.2.2-py3-none-any.whl size=22705 sha256=fa8435f6a89400f046c5992532822b9f8e8d276c4ce47e5c19fd15ecb85410fa\n",
      "  Stored in directory: c:\\users\\18593\\appdata\\local\\pip\\cache\\wheels\\31\\b2\\ad\\42b7be8b127679f56bead529ee324fb5c7d97913e977482a25\n",
      "Successfully built krakenex\n",
      "Installing collected packages: krakenex\n",
      "Successfully installed krakenex-2.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install krakenex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d9a46d93-f3e7-457d-bd80-34071cb762b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Connected to Kraken API!\n"
     ]
    }
   ],
   "source": [
    "import krakenex\n",
    "\n",
    "# ðŸ”‘ Replace with your Kraken API Keys\n",
    "KRAKEN_API_KEY = \"rWNGTgOafgo0PP+zWK2j0YQ4q/r8d+eGllb6szpk3KJ4PhMI/fa0BKia\"  # âœ… CORRECT!\n",
    "KRAKEN_API_SECRET = \"uCU6V5/jRuIG2ugu6M6ZImMr8yWDmthfWjokHny1OkbjWrQI/8ju3IL7/IzklTgvBAku7putrMK6lf79Uc5psw==\"  # âœ… CORRECT!\n",
    "\n",
    "\n",
    "# Authenticate with Kraken\n",
    "kraken = krakenex.API(key=KRAKEN_API_KEY, secret=KRAKEN_API_SECRET)\n",
    "\n",
    "print(\"âœ… Connected to Kraken API!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9c45b424-45a6-4b89-b6df-a359c5c7c4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Connected to Kraken API!\n"
     ]
    }
   ],
   "source": [
    "import krakenex\n",
    "\n",
    "# ðŸ”‘ Replace with your Kraken API Keys\n",
    "KRAKEN_API_KEY = \"rWNGTgOafgo0PP+zWK2j0YQ4q/r8d+eGllb6szpk3KJ4PhMI/fa0BKia\"  # âœ… CORRECT!\n",
    "KRAKEN_API_SECRET = \"uCU6V5/jRuIG2ugu6M6ZImMr8yWDmthfWjokHny1OkbjWrQI/8ju3IL7/IzklTgvBAku7putrMK6lf79Uc5psw==\"  # âœ… CORRECT!\n",
    "\n",
    "\n",
    "# Authenticate with Kraken\n",
    "kraken = krakenex.API(key=KRAKEN_API_KEY, secret=KRAKEN_API_SECRET)\n",
    "\n",
    "print(\"âœ… Connected to Kraken API!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a17145b8-f4d8-4cf5-b5a5-4216011188db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’° Kraken Balance: {'XXBT': '0.0002620000'}\n"
     ]
    }
   ],
   "source": [
    "import krakenex\n",
    "\n",
    "# Authenticate with Kraken API\n",
    "kraken = krakenex.API(key=KRAKEN_API_KEY, secret=KRAKEN_API_SECRET)\n",
    "\n",
    "# Test API connection\n",
    "try:\n",
    "    response = kraken.query_private(\"Balance\")\n",
    "    print(\"ðŸ’° Kraken Balance:\", response[\"result\"])\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error fetching balance: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f2864e50-c7ef-4d66-8487-332b9332d776",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'talib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtalib\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Load BTC price data\u001b[39;00m\n\u001b[0;32m      6\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbtc_usdt_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'talib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib\n",
    "\n",
    "# Load BTC price data\n",
    "df = pd.read_csv(\"btc_usdt_data.csv\")  \n",
    "\n",
    "# ðŸ“ˆ Moving Averages\n",
    "df[\"SMA_20\"] = talib.SMA(df[\"close\"], timeperiod=20)  # 20-day simple moving average\n",
    "df[\"EMA_20\"] = talib.EMA(df[\"close\"], timeperiod=20)  # 20-day exponential moving average\n",
    "\n",
    "# ðŸ“Š RSI (Momentum Indicator)\n",
    "df[\"RSI_14\"] = talib.RSI(df[\"close\"], timeperiod=14)  \n",
    "\n",
    "# ðŸ”„ MACD (Trend Reversal Indicator)\n",
    "df[\"MACD\"], df[\"MACD_signal\"], df[\"MACD_hist\"] = talib.MACD(df[\"close\"], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "\n",
    "# ðŸŽ¯ Bollinger Bands (Volatility Indicator)\n",
    "df[\"Upper_Band\"], df[\"Middle_Band\"], df[\"Lower_Band\"] = talib.BBANDS(df[\"close\"], timeperiod=20, nbdevup=2, nbdevdn=2)\n",
    "\n",
    "# ðŸ“¢ Volume Analysis\n",
    "df[\"Volume_SMA_20\"] = talib.SMA(df[\"volume\"], timeperiod=20)\n",
    "\n",
    "# ðŸŒŽ Sentiment Scores (Twitter, Google Trends, News)\n",
    "df[\"Twitter_Sentiment\"] = twitter_sentiment\n",
    "df[\"Google_Trends\"] = google_trends_score\n",
    "df[\"News_Sentiment\"] = news_sentiment\n",
    "\n",
    "# Drop NaN values (some indicators take time to calculate)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "print(\"âœ… Advanced AI Training Data Ready!\")\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "99ef6515-54ab-4d02-83c8-6dfff51c6fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ta-lib\n",
      "  Downloading ta_lib-0.6.3.tar.gz (376 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: setuptools in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from ta-lib) (75.8.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from ta-lib) (2.2.2)\n",
      "Building wheels for collected packages: ta-lib\n",
      "  Building wheel for ta-lib (pyproject.toml): started\n",
      "  Building wheel for ta-lib (pyproject.toml): finished with status 'error'\n",
      "Failed to build ta-lib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for ta-lib (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [32 lines of output]\n",
      "  <string>:83: UserWarning: Cannot find ta-lib library, installation may fail.\n",
      "  C:\\Users\\18593\\AppData\\Local\\Temp\\pip-build-env-ns2uvvo9\\overlay\\Lib\\site-packages\\setuptools\\config\\_apply_pyprojecttoml.py:81: SetuptoolsWarning: `install_requires` overwritten in `pyproject.toml` (dependencies)\n",
      "    corresp(dist, value, root_dir)\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\\lib.win-amd64-cpython-313\\talib\n",
      "  copying talib\\abstract.py -> build\\lib.win-amd64-cpython-313\\talib\n",
      "  copying talib\\deprecated.py -> build\\lib.win-amd64-cpython-313\\talib\n",
      "  copying talib\\stream.py -> build\\lib.win-amd64-cpython-313\\talib\n",
      "  copying talib\\__init__.py -> build\\lib.win-amd64-cpython-313\\talib\n",
      "  running egg_info\n",
      "  writing ta_lib.egg-info\\PKG-INFO\n",
      "  writing dependency_links to ta_lib.egg-info\\dependency_links.txt\n",
      "  writing requirements to ta_lib.egg-info\\requires.txt\n",
      "  writing top-level names to ta_lib.egg-info\\top_level.txt\n",
      "  reading manifest file 'ta_lib.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  adding license file 'LICENSE'\n",
      "  adding license file 'AUTHORS'\n",
      "  writing manifest file 'ta_lib.egg-info\\SOURCES.txt'\n",
      "  copying talib\\_abstract.pxi -> build\\lib.win-amd64-cpython-313\\talib\n",
      "  copying talib\\_common.pxi -> build\\lib.win-amd64-cpython-313\\talib\n",
      "  copying talib\\_func.pxi -> build\\lib.win-amd64-cpython-313\\talib\n",
      "  copying talib\\_stream.pxi -> build\\lib.win-amd64-cpython-313\\talib\n",
      "  copying talib\\_ta_lib.c -> build\\lib.win-amd64-cpython-313\\talib\n",
      "  copying talib\\_ta_lib.pyi -> build\\lib.win-amd64-cpython-313\\talib\n",
      "  copying talib\\_ta_lib.pyx -> build\\lib.win-amd64-cpython-313\\talib\n",
      "  copying talib\\py.typed -> build\\lib.win-amd64-cpython-313\\talib\n",
      "  running build_ext\n",
      "  building 'talib._ta_lib' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for ta-lib\n",
      "ERROR: Failed to build installable wheels for some pyproject.toml based projects (ta-lib)\n"
     ]
    }
   ],
   "source": [
    "!pip install ta-lib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f247166c-202d-4735-b6d3-e2de5c424215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for ta-lib (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [32 lines of output]\n",
      "  <string>:83: UserWarning: Cannot find ta-lib library, installation may fail.\n",
      "  C:\\Users\\18593\\AppData\\Local\\Temp\\pip-build-env-_ffjg9sg\\overlay\\Lib\\site-packages\\setuptools\\config\\_apply_pyprojecttoml.py:81: SetuptoolsWarning: `install_requires` overwritten in `pyproject.toml` (dependencies)\n",
      "    corresp(dist, value, root_dir)\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\\lib.win-amd64-cpython-313\\talib\n",
      "  copying talib\\abstract.py -> build\\lib.win-amd64-cpython-313\\talib\n",
      "  copying talib\\deprecated.py -> build\\lib.win-amd64-cpython-313\\talib\n",
      "  copying talib\\stream.py -> build\\lib.win-amd64-cpython-313\\talib\n",
      "  copying talib\\__init__.py -> build\\lib.win-amd64-cpython-313\\talib\n",
      "  running egg_info\n",
      "  writing ta_lib.egg-info\\PKG-INFO\n",
      "  writing dependency_links to ta_lib.egg-info\\dependency_links.txt\n",
      "  writing requirements to ta_lib.egg-info\\requires.txt\n",
      "  writing top-level names to ta_lib.egg-info\\top_level.txt\n",
      "  reading manifest file 'ta_lib.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  adding license file 'LICENSE'\n",
      "  adding license file 'AUTHORS'\n",
      "  writing manifest file 'ta_lib.egg-info\\SOURCES.txt'\n",
      "  copying talib\\_abstract.pxi -> build\\lib.win-amd64-cpython-313\\talib\n",
      "  copying talib\\_common.pxi -> build\\lib.win-amd64-cpython-313\\talib\n",
      "  copying talib\\_func.pxi -> build\\lib.win-amd64-cpython-313\\talib\n",
      "  copying talib\\_stream.pxi -> build\\lib.win-amd64-cpython-313\\talib\n",
      "  copying talib\\_ta_lib.c -> build\\lib.win-amd64-cpython-313\\talib\n",
      "  copying talib\\_ta_lib.pyi -> build\\lib.win-amd64-cpython-313\\talib\n",
      "  copying talib\\_ta_lib.pyx -> build\\lib.win-amd64-cpython-313\\talib\n",
      "  copying talib\\py.typed -> build\\lib.win-amd64-cpython-313\\talib\n",
      "  running build_ext\n",
      "  building 'talib._ta_lib' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for ta-lib\n",
      "ERROR: Failed to build installable wheels for some pyproject.toml based projects (ta-lib)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ta-lib\n",
      "  Using cached ta_lib-0.6.3.tar.gz (376 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: setuptools in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from ta-lib) (75.8.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from ta-lib) (2.2.2)\n",
      "Building wheels for collected packages: ta-lib\n",
      "  Building wheel for ta-lib (pyproject.toml): started\n",
      "  Building wheel for ta-lib (pyproject.toml): finished with status 'error'\n",
      "Failed to build ta-lib\n"
     ]
    }
   ],
   "source": [
    "pip install ta-lib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5512013d-b2e4-4866-a6b2-a1900927662f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… AI Model Saved!\n",
      "âœ… Dataset Saved!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Save trained AI model\n",
    "with open(\"ai_trading_model.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "print(\"âœ… AI Model Saved!\")\n",
    "\n",
    "# Save preprocessed dataset\n",
    "df.to_csv(\"ai_trading_data.csv\", index=False)\n",
    "print(\"âœ… Dataset Saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6e437e22-907a-40bf-9839-3d4e3d2ede8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: %autosave requires an integer, got '30  # Save every 30 seconds'\n"
     ]
    }
   ],
   "source": [
    "%autosave 30  # Save every 30 seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb5ab1d-628f-4aa6-9f79-7a3d48ef556e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "04f4d806-7459-4cfa-a525-3e8e5850469b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API Keys Loaded Securely!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API keys from .env file\n",
    "load_dotenv()\n",
    "\n",
    "KRAKEN_API_KEY = os.getenv(\"KRAKEN_API_KEY\")\n",
    "KRAKEN_API_SECRET = os.getenv(\"KRAKEN_API_SECRET\")\n",
    "\n",
    "print(\"âœ… API Keys Loaded Securely!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24fc27af-1c91-449d-8929-a87b8e5bf768",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'twitter_sentiment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVolume_SMA_20\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m talib\u001b[38;5;241m.\u001b[39mSMA(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvolume\u001b[39m\u001b[38;5;124m\"\u001b[39m], timeperiod\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# ðŸŒŽ Sentiment Scores (Twitter, Google Trends, News)\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTwitter_Sentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtwitter_sentiment\u001b[49m\n\u001b[0;32m     26\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGoogle_Trends\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m google_trends_score\n\u001b[0;32m     27\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNews_Sentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m news_sentiment\n",
      "\u001b[1;31mNameError\u001b[0m: name 'twitter_sentiment' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib\n",
    "\n",
    "# Load BTC price data\n",
    "df = pd.read_csv(\"btc_usdt_data.csv\")  \n",
    "\n",
    "# ðŸ“ˆ Moving Averages\n",
    "df[\"SMA_20\"] = talib.SMA(df[\"close\"], timeperiod=20)  # 20-day simple moving average\n",
    "df[\"EMA_20\"] = talib.EMA(df[\"close\"], timeperiod=20)  # 20-day exponential moving average\n",
    "\n",
    "# ðŸ“Š RSI (Momentum Indicator)\n",
    "df[\"RSI_14\"] = talib.RSI(df[\"close\"], timeperiod=14)  \n",
    "\n",
    "# ðŸ”„ MACD (Trend Reversal Indicator)\n",
    "df[\"MACD\"], df[\"MACD_signal\"], df[\"MACD_hist\"] = talib.MACD(df[\"close\"], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "\n",
    "# ðŸŽ¯ Bollinger Bands (Volatility Indicator)\n",
    "df[\"Upper_Band\"], df[\"Middle_Band\"], df[\"Lower_Band\"] = talib.BBANDS(df[\"close\"], timeperiod=20, nbdevup=2, nbdevdn=2)\n",
    "\n",
    "# ðŸ“¢ Volume Analysis\n",
    "df[\"Volume_SMA_20\"] = talib.SMA(df[\"volume\"], timeperiod=20)\n",
    "\n",
    "# ðŸŒŽ Sentiment Scores (Twitter, Google Trends, News)\n",
    "df[\"Twitter_Sentiment\"] = twitter_sentiment\n",
    "df[\"Google_Trends\"] = google_trends_score\n",
    "df[\"News_Sentiment\"] = news_sentiment\n",
    "\n",
    "# Drop NaN values (some indicators take time to calculate)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "print(\"âœ… Advanced AI Training Data Ready!\")\n",
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c25e14f-1e07-4aea-868b-62b3359816a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: ccxt in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (4.4.65)\n",
      "Requirement already satisfied: setuptools>=60.9.0 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from ccxt) (75.8.0)\n",
      "Requirement already satisfied: certifi>=2018.1.18 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from ccxt) (2025.1.31)\n",
      "Requirement already satisfied: requests>=2.18.4 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from ccxt) (2.32.3)\n",
      "Requirement already satisfied: cryptography>=2.6.1 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from ccxt) (44.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from ccxt) (4.12.2)\n",
      "Requirement already satisfied: aiohttp<=3.10.11 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from ccxt) (3.10.11)\n",
      "Requirement already satisfied: aiodns>=1.1.1 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from ccxt) (3.2.0)\n",
      "Requirement already satisfied: yarl>=1.7.2 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from ccxt) (1.18.3)\n",
      "Requirement already satisfied: pycares>=4.0.0 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from aiodns>=1.1.1->ccxt) (4.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<=3.10.11->ccxt) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<=3.10.11->ccxt) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<=3.10.11->ccxt) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<=3.10.11->ccxt) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from aiohttp<=3.10.11->ccxt) (6.1.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from cryptography>=2.6.1->ccxt) (1.17.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.18.4->ccxt) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.18.4->ccxt) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from requests>=2.18.4->ccxt) (2.3.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from yarl>=1.7.2->ccxt) (0.2.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\18593\\appdata\\roaming\\python\\python313\\site-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt) (2.22)\n"
     ]
    }
   ],
   "source": [
    "pip install ccxt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd8ff72e-17d0-43c1-a7f6-988ac59cf84c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ExchangeNotAvailable",
     "evalue": "binance GET https://api.binance.com/api/v3/exchangeInfo 451  {\n  \"code\": 0,\n  \"msg\": \"Service unavailable from a restricted location according to 'b. Eligibility' in https://www.binance.com/en/terms. Please contact customer service if you believe you received this message in error.\"\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\ccxt\\base\\exchange.py:573\u001b[0m, in \u001b[0;36mExchange.fetch\u001b[1;34m(self, url, method, headers, body)\u001b[0m\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, Response: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, method, url, http_status_code, headers, http_response)\n\u001b[1;32m--> 573\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Timeout \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 451 Client Error:  for url: https://api.binance.com/api/v3/exchangeInfo",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mExchangeNotAvailable\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mccxt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m binance \u001b[38;5;241m=\u001b[39m ccxt\u001b[38;5;241m.\u001b[39mbinance()\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mbinance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_ticker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBTC/USDT\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\ccxt\\binance.py:4282\u001b[0m, in \u001b[0;36mbinance.fetch_ticker\u001b[1;34m(self, symbol, params)\u001b[0m\n\u001b[0;32m   4267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfetch_ticker\u001b[39m(\u001b[38;5;28mself\u001b[39m, symbol: \u001b[38;5;28mstr\u001b[39m, params\u001b[38;5;241m=\u001b[39m{}) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Ticker:\n\u001b[0;32m   4268\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4269\u001b[0m \u001b[38;5;124;03m    fetches a price ticker, a statistical calculation with the information calculated over the past 24 hours for a specific market\u001b[39;00m\n\u001b[0;32m   4270\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4280\u001b[0m \u001b[38;5;124;03m    :returns dict: a `ticker structure <https://docs.ccxt.com/#/?id=ticker-structure>`\u001b[39;00m\n\u001b[0;32m   4281\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4282\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_markets\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4283\u001b[0m     market \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmarket(symbol)\n\u001b[0;32m   4284\u001b[0m     request: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m   4285\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msymbol\u001b[39m\u001b[38;5;124m'\u001b[39m: market[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   4286\u001b[0m     }\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\ccxt\\base\\exchange.py:1509\u001b[0m, in \u001b[0;36mExchange.load_markets\u001b[1;34m(self, reload, params)\u001b[0m\n\u001b[0;32m   1507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfetchCurrencies\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m   1508\u001b[0m     currencies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfetch_currencies()\n\u001b[1;32m-> 1509\u001b[0m markets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch_markets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_markets(markets, currencies)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\ccxt\\binance.py:3220\u001b[0m, in \u001b[0;36mbinance.fetch_markets\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m   3218\u001b[0m marketType \u001b[38;5;241m=\u001b[39m fetchMarkets[i]\n\u001b[0;32m   3219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m marketType \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspot\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m-> 3220\u001b[0m     promisesRaw\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublicGetExchangeInfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   3221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m fetchMargins \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_required_credentials(\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sandboxMode:\n\u001b[0;32m   3222\u001b[0m         promisesRaw\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msapiGetMarginAllPairs(params))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\ccxt\\base\\types.py:35\u001b[0m, in \u001b[0;36mEntry.__init__.<locals>.unbound_method\u001b[1;34m(_self, params)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21munbound_method\u001b[39m(_self, params\u001b[38;5;241m=\u001b[39m{}):\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_self\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\ccxt\\binance.py:11483\u001b[0m, in \u001b[0;36mbinance.request\u001b[1;34m(self, path, api, method, params, headers, body, config)\u001b[0m\n\u001b[0;32m  11482\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrequest\u001b[39m(\u001b[38;5;28mself\u001b[39m, path, api\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublic\u001b[39m\u001b[38;5;124m'\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m'\u001b[39m, params\u001b[38;5;241m=\u001b[39m{}, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, config\u001b[38;5;241m=\u001b[39m{}):\n\u001b[1;32m> 11483\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  11484\u001b[0m     \u001b[38;5;66;03m# a workaround for {\"code\":-2015,\"msg\":\"Invalid API-key, IP, or permissions for action.\"}\u001b[39;00m\n\u001b[0;32m  11485\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m api \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprivate\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\ccxt\\base\\exchange.py:4355\u001b[0m, in \u001b[0;36mExchange.fetch2\u001b[1;34m(self, path, api, method, params, headers, body, config)\u001b[0m\n\u001b[0;32m   4353\u001b[0m                 \u001b[38;5;66;03m# continue  #check self\u001b[39;00m\n\u001b[0;32m   4354\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m retries:\n\u001b[1;32m-> 4355\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m   4356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\ccxt\\base\\exchange.py:4345\u001b[0m, in \u001b[0;36mExchange.fetch2\u001b[1;34m(self, path, api, method, params, headers, body, config)\u001b[0m\n\u001b[0;32m   4343\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, retries \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   4344\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 4345\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43murl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmethod\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mheaders\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbody\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4346\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   4347\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, NetworkError):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\ccxt\\base\\exchange.py:591\u001b[0m, in \u001b[0;36mExchange.fetch\u001b[1;34m(self, url, method, headers, body)\u001b[0m\n\u001b[0;32m    589\u001b[0m     skip_further_error_handling \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_errors(http_status_code, http_status_text, url, method, headers, http_response, json_response, request_headers, request_body)\n\u001b[0;32m    590\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_further_error_handling:\n\u001b[1;32m--> 591\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_http_status_code\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_status_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_status_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_response\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ExchangeError(details) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requestsConnectionError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\ccxt\\base\\exchange.py:1687\u001b[0m, in \u001b[0;36mExchange.handle_http_status_code\u001b[1;34m(self, code, reason, url, method, body)\u001b[0m\n\u001b[0;32m   1685\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m codeAsString \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttpExceptions:\n\u001b[0;32m   1686\u001b[0m     ErrorClass \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttpExceptions[codeAsString]\n\u001b[1;32m-> 1687\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ErrorClass(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m method \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m url \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m codeAsString \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m reason \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m body)\n",
      "\u001b[1;31mExchangeNotAvailable\u001b[0m: binance GET https://api.binance.com/api/v3/exchangeInfo 451  {\n  \"code\": 0,\n  \"msg\": \"Service unavailable from a restricted location according to 'b. Eligibility' in https://www.binance.com/en/terms. Please contact customer service if you believe you received this message in error.\"\n}"
     ]
    }
   ],
   "source": [
    "import ccxt\n",
    "binance = ccxt.binance()\n",
    "print(binance.fetch_ticker('BTC/USDT'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cccc4043-c585-4127-ab7c-c51ab7c823e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (720029327.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[7], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install web3\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install web3\n",
    "pip install eth_abi\n",
    "pip install requests\n",
    "pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e0445dd-598a-4462-a29d-c6a20d5d51cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3829576552.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    pip install web3\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install web3\n",
    "pip install eth_abi\n",
    "pip install requests\n",
    "pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18baa21f-2b4d-4bb5-9955-ab755b6bd9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.8.0\n"
     ]
    }
   ],
   "source": [
    "import web3\n",
    "print(web3.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e98028f0-89c4-42f1-b390-a44856c5ed49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection failed âŒ\n"
     ]
    }
   ],
   "source": [
    "from web3 import Web3\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Connect to Ethereum (Use Infura or Alchemy for a reliable RPC)\n",
    "INFURA_URL = \"c69d6b44ab8e42cb852986f3b686fe5e\"  # Replace with your Infura key\n",
    "w3 = Web3(Web3.HTTPProvider(INFURA_URL))\n",
    "\n",
    "# Check if connected\n",
    "if w3.is_connected():\n",
    "    print(\"Connected to Ethereum âœ…\")\n",
    "else:\n",
    "    print(\"Connection failed âŒ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08e028c1-132a-4a76-96f7-e816353854bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Connection failed\n"
     ]
    }
   ],
   "source": [
    "from web3 import Web3\n",
    "\n",
    "INFURA_URL = \"https://mainnet.infura.io/v3/YOUR_INFURA_PROJECT_ID\"\n",
    "w3 = Web3(Web3.HTTPProvider(INFURA_URL))\n",
    "\n",
    "if w3.is_connected():\n",
    "    print(\"âœ… Connected to Ethereum Mainnet\")\n",
    "else:\n",
    "    print(\"âŒ Connection failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37c73bea-0a84-4929-b796-27b007e117d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALCHEMY_URL = \"https://eth-mainnet.alchemyapi.io/v2/r5ksXbXmjmB1_3AYi1DG4A868rhNp2tg\"\n",
    "w3 = Web3(Web3.HTTPProvider(ALCHEMY_URL))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e9af62-3c21-43e7-a467-b662d8444cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
